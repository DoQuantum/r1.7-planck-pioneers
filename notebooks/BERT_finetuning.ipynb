{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Invalid requirement: 'transformers,': Expected end or semicolon (after name and no valid version specifier)\n",
            "    transformers,\n",
            "                ^\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers, torch, numpy, matplotlib, seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Attention Mechanisms with Real Token Embeddings and Transformers\n",
        "\n",
        "This notebook extends the previous conceptual explanation by incorporating **real token embeddings** and demonstrating how **attention mechanisms** (dense and sparse) are used in an actual Transformer model.\n",
        "\n",
        "You will learn:\n",
        "- How token embeddings are generated from real text using a BERT tokenizer\n",
        "- How dense attention works using these embeddings\n",
        "- How to simulate sparse attention on embeddings\n",
        "- How to pass data through a pretrained BERT model and inspect its attention weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Tokenization and Real Embeddings\n",
        "We will use Hugging Face's Transformers library to tokenize text and extract token embeddings from BERT.\n",
        "\n",
        "**Common special tokens include:**\n",
        "- `[CLS]`: A classification token added at the beginning of every sequence. Its final hidden state is often used as a summary representation for classification tasks.\n",
        "- `[SEP]`: A separator token used to distinguish between two sentences or segments in tasks like question answering or next sentence prediction.\n",
        "- `[PAD]`: A padding token used to make sequences the same length in a batch. It tells the model to ignore these tokens during attention and loss computation.\n",
        "- `[MASK]`: Used in masked language modeling (e.g., during BERT pretraining). It indicates which token is masked and should be predicted by the model.\n",
        "\n",
        "    These tokens are embedded just like regular words but carry special meaning in how the model interprets and attends to the input.\n",
        "\n",
        "**Question: What are embeddings?**\n",
        "Embeddings are vector representations of words or tokens that capture semantic meaning. In BERT, the embedding layer turns each token into a 768-dimensional vector (for BERT-base).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens: ['[CLS]', 'the', 'cat', 'sat', 'on', 'the', 'mat', '.', '[SEP]']\n",
            "Embeddings shape: torch.Size([9, 768])\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased', output_attentions=True)\n",
        "model.eval()\n",
        "\n",
        "# Sample sentence\n",
        "sentence = \"The cat sat on the mat.\"\n",
        "inputs = tokenizer(sentence, return_tensors='pt')\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.squeeze(0)  # (seq_len, hidden_dim)\n",
        "    attentions = outputs.attentions  # list of attention matrices from all layers\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "print(f\"Tokens: {tokens}\")\n",
        "print(f\"Embeddings shape: {embeddings.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Visualizing Real Dense Attention\n",
        "BERT uses multi-head self-attention. We'll visualize one head from the first layer.\n",
        "\n",
        "**Question: What is multi-head attention?**\n",
        "Instead of one attention mechanism, BERT uses multiple parallel heads (e.g., 12 in BERT-base), each learning to focus on different aspects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Extract attention from layer 0, head 0\n",
        "attn_matrix = attentions[0][0, 0].numpy()  # (seq_len, seq_len)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(attn_matrix, xticklabels=tokens, yticklabels=tokens, cmap=\"Blues\", annot=False)\n",
        "plt.title(\"BERT Dense Attention (Layer 0, Head 0)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Understanding Layers and Attention Heads in BERT\n",
        "\n",
        "To understand how attention works in BERT, it's important to know how the model is structured internally. BERT is made up of multiple layers, and each layer contains multiple attention heads."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Simulating Sparse Attention\n",
        "We will mask out parts of the attention matrix to simulate a sparse attention pattern (e.g., sliding window).\n",
        "\n",
        "**Note**: This does not re-run BERT with sparse attention, but it helps conceptually understand how sparse patterns work.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Simulate sparse attention by masking\n",
        "def apply_sparse_mask(attn, window_size=2):\n",
        "    n = attn.shape[0]\n",
        "    mask = np.zeros_like(attn)\n",
        "    for i in range(n):\n",
        "        for j in range(max(0, i - window_size), min(n, i + window_size + 1)):\n",
        "            mask[i, j] = 1\n",
        "    return attn * mask\n",
        "\n",
        "sparse_attn = apply_sparse_mask(attn_matrix, window_size=2)\n",
        "sparse_attn /= sparse_attn.sum(axis=1, keepdims=True)  # Renormalize\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(sparse_attn, xticklabels=tokens, yticklabels=tokens, cmap=\"Oranges\", annot=False)\n",
        "plt.title(\"Simulated Sparse Attention (Window Size = 2)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Summary and Use Cases\n",
        "- We used real BERT token embeddings and attention matrices.\n",
        "- Dense attention allows full context but is costly.\n",
        "- Sparse attention reduces cost by limiting which tokens attend to which.\n",
        "- Useful for long documents, streaming input, and memory-efficient training.\n",
        "\n",
        "**Question: Can we actually train BERT with sparse attention?**\n",
        "Yes. Frameworks like Longformer, BigBird, and custom sparse BERT variants support this. They replace the full attention layers with custom sparse versions and compare results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploring BERT Attention: From Interpretation to Fine-Tuning\n",
        "\n",
        "In this notebook, we will **explore how BERT uses attention mechanisms** to understand text, without diving straight into training. We’ll:\n",
        "\n",
        "1. **Visualize BERT's attention heads**: What do they attend to? Are there patterns at different layers?\n",
        "2. **Fine-tune the last attention layer and a classifier** on the IMDB sentiment dataset.\n",
        "3. **Compare attention before and after fine-tuning** to observe how attention adapts during learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1 🔍 Understanding Pretrained Attention\n",
        "\n",
        "BERT uses **multi-layer, multi-head self-attention** to understand relationships between tokens.  \n",
        "Each layer in BERT contains multiple attention heads — and each head might focus on different aspects:\n",
        "\n",
        "- Syntactic roles (e.g., subject → verb)\n",
        "- Semantic similarity (e.g., synonyms)\n",
        "- Special tokens ([CLS], [SEP], etc.)\n",
        "\n",
        "### 📌 Objective\n",
        "\n",
        "In this section, we will:\n",
        "\n",
        "- Load a **lightweight, distilled BERT** model (xtremedistil) for faster visualization.  \n",
        "- Pass a sentence through the model.  \n",
        "- Visualize and compare the **attention maps** at **different layers** and **heads**.  \n",
        "This will help us intuitively understand how BERT processes and attends to the input text.\n",
        "\n",
        "Let’s begin by loading the model and tokenizer!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 256, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 256)\n",
              "    (token_type_embeddings): Embedding(2, 256)\n",
              "    (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-5): 6 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 1: Load BERT model and tokenizer (xtremedistil for speed)\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "import torch\n",
        "\n",
        "# Load tokenizer and model\n",
        "model_name = \"microsoft/xtremedistil-l6-h256-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "config = AutoConfig.from_pretrained(model_name, output_attentions=True)\n",
        "model = AutoModel.from_pretrained(model_name, config=config)\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔧 Step 2: Tokenize Input and Extract Attention Weights\n",
        "\n",
        "Now that we've loaded our distilled BERT model and tokenizer, let's walk through the process of running a sentence through the model and capturing its **attention weights**.\n",
        "\n",
        "#### 🔍 Line-by-line Explanation\n",
        "\n",
        "1. We define a test sentence. Our goal is to understand how BERT internally pays attention across these words.\n",
        "2. We tokenize the sentence into input IDs and attention masks, and return them as PyTorch tensors (required for BERT).\n",
        "3. We pass the inputs to the model inside a `torch.no_grad()` block — since we're just doing inference and don't need gradients.\n",
        "\n",
        "We collect the attention weights for each layer (BERT returns them as a tuple). Each element contains one layer's attention of shape:\n",
        "- `batch_size = 1` (since it's one sentence)\n",
        "- `num_heads = 8`\n",
        "- `seq_len = number of tokens` (e.g., 13 if including special tokens)\n",
        "    \n",
        "So we end up with: `torch.Size([6, 1, 8, seq_len, seq_len])`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([6, 1, 8, 13, 13])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence = \"The movie was surprisingly good, I really enjoyed it!\"\n",
        "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "\n",
        "# Forward pass with attentions\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Extract attention weights\n",
        "# shape: (num_layers, batch, num_heads, seq_len, seq_len)\n",
        "attentions = torch.stack(outputs.attentions)  # 6 layers\n",
        "attentions.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🧠 Step 3: Inspect Attention Tensor Dimensions and Tokens\n",
        "\n",
        "Now that we’ve extracted the attention weights, let’s understand **what we’re working with**.\n",
        "\n",
        "We want to:\n",
        "\n",
        "1. **Verify** the shape of the attention tensor.\n",
        "2. **List the input tokens** (as BERT sees them).\n",
        "3. **Understand** what each axis of the attention tensor means.\n",
        "\n",
        "#### Attention Shape Breakdown\n",
        "\n",
        "- `attentions.shape → (num_layers, batch, num_heads, seq_len, seq_len)`\n",
        "- Each matrix inside has shape `(seq_len, seq_len)`:\n",
        "  - **Rows** are *query positions* (i.e., \"who is attending\")\n",
        "  - **Columns** are *key positions* (i.e., \"who is being attended to\")\n",
        "\n",
        "We'll also print the actual BERT tokens so we can interpret the matrices meaningfully.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 6, Heads: 8, Tokens: 13\n",
            "\n",
            "BERT tokens:\n",
            "['[CLS]', 'the', 'movie', 'was', 'surprisingly', 'good', ',', 'i', 'really', 'enjoyed', 'it', '!', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "# Unpack attention tensor dimensions\n",
        "num_layers, batch_size, num_heads, seq_len, _ = attentions.shape\n",
        "print(f\"Layers: {num_layers}, Heads: {num_heads}, Tokens: {seq_len}\")\n",
        "\n",
        "# Decode tokens\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "print(\"\\nBERT tokens:\")\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🎨 Step 4: Visualize Attention Across All Heads in a Layer\n",
        "\n",
        "Now that we understand the attention tensor structure and the tokens, let’s **visualize how each head behaves in a given layer**.\n",
        "\n",
        "Instead of just picking one head, we’ll look at **all attention heads** in a chosen layer using a grid of heatmaps.\n",
        "\n",
        "#### 🔍 What This Visualization Shows\n",
        "\n",
        "- Each subplot represents the attention matrix of **one head** in the selected layer.\n",
        "- The matrix shows how each token attends to every other token.\n",
        "- **Rows** = queries (the attending token),  \n",
        "  **Columns** = keys (the token being attended to).\n",
        "- Color intensity indicates attention strength.\n",
        "\n",
        "#### 🎛 Interactive Tool\n",
        "\n",
        "You can use a slider to choose the layer you want to inspect.  \n",
        "This allows you to see **how attention patterns evolve across BERT layers** — some attend broadly, others sharply focus on key tokens like `[CLS]`, verbs, or punctuation.\n",
        "\n",
        "Let’s run the interactive tool!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipywidgets in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (8.1.7)\n",
            "Requirement already satisfied: comm>=0.1.3 in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from ipywidgets) (9.3.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: colorama in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
            "Requirement already satisfied: decorator in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: stack_data in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: pure_eval in c:\\users\\evren\\anaconda3\\envs\\planckteam\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created dictionary with 6 layers\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dd063c74da44893a31c1a74cf34f51b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='layer', max=5), Output()), _dom_classes=('widget-interac…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import numpy as np\n",
        "from ipywidgets import interact, IntSlider\n",
        "\n",
        "def extract_attention_by_layers(attention_matrix):\n",
        "    \"\"\"Extract attention into a dictionary by layers.\"\"\"\n",
        "    num_layers = attention_matrix.shape[0]\n",
        "    attention_by_layer = {}\n",
        "    \n",
        "    for layer in range(num_layers):\n",
        "        # Store all heads for this layer\n",
        "        attention_by_layer[f\"layer_{layer}\"] = attention_matrix[layer].detach().clone()\n",
        "    \n",
        "    return attention_by_layer\n",
        "\n",
        "def plot_all_heads_in_layer(tokens, attention_matrix, layer=0, num_heads=None):\n",
        "    if num_heads is None:\n",
        "        num_heads = attention_matrix.shape[2]  # Get number of heads\n",
        "    \n",
        "    fig, axes = plt.subplots(nrows=int(np.ceil(num_heads/4)), ncols=min(4, num_heads), \n",
        "                           figsize=(16, 3*int(np.ceil(num_heads/4))))\n",
        "    axes = axes.flatten() if hasattr(axes, 'flatten') else [axes]\n",
        "    \n",
        "    for head_idx in range(num_heads):\n",
        "        attn = attention_matrix[layer, 0, head_idx].detach().numpy()\n",
        "        ax = axes[head_idx]\n",
        "        sns.heatmap(attn, xticklabels=tokens, yticklabels=tokens, \n",
        "                   cmap=\"viridis\", ax=ax, cbar=False)\n",
        "        ax.set_title(f\"Head {head_idx}\")\n",
        "        ax.set_xlabel(\"\")\n",
        "        ax.set_ylabel(\"\")\n",
        "        ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
        "        ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
        "    \n",
        "    # Add a common colorbar\n",
        "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
        "    fig.colorbar(axes[0].collections[0], cax=cbar_ax)\n",
        "    \n",
        "    plt.suptitle(f\"All Attention Heads in Layer {layer}\", fontsize=16)\n",
        "    plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n",
        "    return fig\n",
        "\n",
        "def interactive_layer_attention(tokens, attention_matrix):\n",
        "    num_layers = attention_matrix.shape[0]\n",
        "    \n",
        "    # Create dictionary with attention by layers\n",
        "    attention_by_layer = extract_attention_by_layers(attention_matrix)\n",
        "    print(f\"Created dictionary with {len(attention_by_layer)} layers\")\n",
        "    \n",
        "    @interact(layer=IntSlider(min=0, max=num_layers-1, step=1, value=0))\n",
        "    def update(layer):\n",
        "        plot_all_heads_in_layer(tokens, attention_matrix, layer)\n",
        "        \n",
        "    return attention_by_layer\n",
        "\n",
        "# Usage:\n",
        "attention_dict = interactive_layer_attention(tokens, attentions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🧠 Key Takeaways — Layer 0 Attention Patterns\n",
        "\n",
        "In Layer 0 of the xtremedistil BERT model, attention heads show **foundational patterns** that prepare for deeper semantic understanding. Here's a **summary** of what each head is doing:\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔹 **Diagonal / Identity Heads**  \n",
        "Preserve each token's representation by mostly attending to itself.  \n",
        "- **Head 0** – strong self-attention\n",
        "\n",
        "#### 🔸 **Directional / Sequential Heads**  \n",
        "Focus on tokens nearby in sequence — useful for grammar and structure.  \n",
        "- **Head 3** – strong previous-token pattern --> attends to **previous token**  \n",
        "- **Head 5** – strong next-token pattern --> attends to **next token**\n",
        "\n",
        "#### 🔻 **Sparse / Focused Heads**  \n",
        "Attend to a few specific tokens (e.g., sentiment words or key phrases). \n",
        "- **Head 1** – All words attending [CLS] and [SEP]\n",
        "- **Head 2** – sparse attention (few strong connections and especially on movie)  \n",
        "- **Head 7** – focuses around the diagonal linking nouns, verbs and adjectives from the same part of the sentence\n",
        "- **Head 4** – [SEP] and [surprisingly] attended broadly  \n",
        "- **Head 6** – [CLS] attended broadly\n",
        "\n",
        "These patterns show how even the **first layer** of BERT begins organizing language:\n",
        "- **Some heads memorize position** or **identity**,  \n",
        "- Others build **early syntactic or phrasal relationships**,  \n",
        "- And some prepare **global summaries** for later use.\n",
        "\n",
        "\n",
        "### 🧠 Key Takeaways — Layer 5 Attention Patterns (Final Layer)\n",
        "\n",
        "In the **last layer** of xtremedistil BERT, attention heads become much more **specialized** and **focused**. They're no longer just preserving structure — they're identifying **key semantic cues** to prepare for downstream tasks like classification or question answering.\n",
        "\n",
        "Here’s how the heads in Layer 5 cluster based on behavior:\n",
        "\n",
        "#### 🔹 **Sentence Anchor / Special Token Focus**\n",
        "Heads that allocate strong attention to sentence-level structural tokens like `[CLS]`, `[SEP]`, or function words.\n",
        "- **Head 0** – Attends to `[CLS]`, `[SEP]`, and mid-sentence context tokens like `movie`, `was`, `surprisingly`, `good`.  \n",
        "- **Head 2** – Balanced across `[CLS]`, `[SEP]`, `was`, `it`, `the`.  \n",
        "- **Head 6** – Strong triple focus on `[CLS]` and `the`, possibly re-centering `[CLS]`.  \n",
        "- **Head 7** – Mostly attends to `was`, but `[CLS]` and `[SEP]` get notable attention too.\n",
        "\n",
        "📌 *Interpretation*: These heads likely support **global summarization**, or feed context to the `[CLS]` token for sentence-level prediction.\n",
        "\n",
        "#### 🔸 **Sentiment Phrase Heads**\n",
        "These heads focus on important **semantic cues or emotional words** in the sentence.\n",
        "- **Head 1** – Attends strongly to `surprisingly`, `good`, `really`, and `enjoyed`.  \n",
        "- **Head 3** – Focuses tightly on `surprisingly` and `was`.  \n",
        "- **Head 5** – Almost exclusively focuses on `was`.\n",
        "\n",
        "📌 *Interpretation*: These heads appear to **lock on to sentiment-bearing phrases**, which is crucial for tasks like **sentiment analysis** or **emotion classification**.\n",
        "\n",
        "#### 🔻 **Token-Level Detail Spreaders**\n",
        "Heads that distribute attention across punctuation, function words, and syntax markers — possibly for fine control.\n",
        "- **Head 4** – Favors tokens like `the`, `movie`, `i`, `it`, punctuation (`,`, `.`).  \n",
        "📌 *Interpretation*: This head may be balancing **token-level refinement** before final decoding, especially for syntactic normalization.\n",
        "\n",
        "### 🎓 Final Note\n",
        "\n",
        "> While Layer 0 built structure and flow, Layer 5 **refines meaning** and consolidates relevance.\n",
        "\n",
        "- **[CLS] is now dominant**, indicating readiness for classification tasks.  \n",
        "- **Key content words** like `good`, `enjoyed`, and `surprisingly` are getting priority.\n",
        "- There's **less uniformity** — each head has its own role in encoding final semantics.\n",
        "\n",
        "This is exactly what we expect from the **last layer of BERT** — every head is now highly **purpose-driven**.\n",
        "\n",
        "\n",
        "--- \n",
        "\n",
        "## 2 🛠 Fine-Tuning BERT on IMDB: Impact on Attention\n",
        "\n",
        "Now that we've seen how a pretrained model distributes attention, the big question is:\n",
        "\n",
        "> **How does attention change when we fine-tune the model for a specific task?**\n",
        "\n",
        "### 🎯 Objective\n",
        "\n",
        "In this section, we will:\n",
        "\n",
        "1. **Fine-tune only the last attention layer** (plus a small classifier head) on the **IMDB sentiment classification dataset**.\n",
        "2. Freeze all other weights — this way, any change in behavior must come from the last attention block and classifier.\n",
        "3. After training, we’ll **re-run attention visualizations** for a test sentence and **compare them to the original pretrained version**.\n",
        "\n",
        "This will help us answer:\n",
        "- Which heads adapt to focus more on sentiment-bearing words?\n",
        "- Does `[CLS]` become more dominant or refined?\n",
        "- Are certain heads re-purposed for the task?\n",
        "\n",
        "Let’s start by loading the IMDB dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': 'There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier\\'s plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have \"clairvoyance\". People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it\\'s the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...', 'label': 1}\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load IMDB dataset\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# We'll just use a small portion to keep things quick and interpretable\n",
        "imdb = load_dataset(\"imdb\")\n",
        "small_train = imdb[\"train\"].shuffle(seed=42).select(range(2000))\n",
        "small_test = imdb[\"test\"].shuffle(seed=42).select(range(500))\n",
        "\n",
        "# Display a sample\n",
        "print(small_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🧼 Step 2: Tokenization and Batching\n",
        "\n",
        "Now that we’ve loaded the IMDB dataset, let’s preprocess the data for BERT input.\n",
        "\n",
        "#### 📋 Key Preprocessing Choices:\n",
        "- **Tokenizer**: We use the same `xtremedistil` tokenizer to keep consistency with the model.\n",
        "- **Truncation**: Reviews are truncated to **64 tokens** for speed and memory efficiency.\n",
        "- **Padding**: Handled dynamically per batch using Hugging Face's `DataCollatorWithPadding`.\n",
        "- **Batched format**: All data is returned as PyTorch tensors for compatibility with the model and training loop.\n",
        "\n",
        "We then create **PyTorch DataLoaders** that will serve batches to the model during training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49a959cb72cd44d295df65db2fe2a75d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': torch.Size([16, 64]), 'attention_mask': torch.Size([16, 64]), 'labels': torch.Size([16])}\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Tokenization & Dataloader setup\n",
        "\n",
        "from transformers import DataCollatorWithPadding\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[\"text\"], truncation=True, padding=True, max_length=64)\n",
        "\n",
        "# Apply tokenization\n",
        "tokenized_train = small_train.map(tokenize_fn, batched=True)\n",
        "tokenized_test  = small_test.map(tokenize_fn, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "tokenized_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "tokenized_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "# Dynamic padding for batches\n",
        "collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
        "\n",
        "# Dataloaders\n",
        "train_loader = DataLoader(tokenized_train, batch_size=16, shuffle=True, collate_fn=collator)\n",
        "test_loader  = DataLoader(tokenized_test, batch_size=16, shuffle=False, collate_fn=collator)\n",
        "\n",
        "# Peek at one batch\n",
        "batch = next(iter(train_loader))\n",
        "print({k: v.shape for k, v in batch.items()})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🧠 Step 3: Freezing BERT & Adding a Classifier on Top\n",
        "\n",
        "We now prepare our model for **fine-tuning**.\n",
        "\n",
        "#### 🎯 Objective:\n",
        "We want to **only fine-tune the last attention layer and a classifier head**. Why?\n",
        "\n",
        "- Lower BERT layers already capture general syntax and semantics.\n",
        "- The **last layer** can adapt to the sentiment task (IMDB) by adjusting how tokens attend to each other.\n",
        "- This setup lets us **observe how attention patterns change** due to fine-tuning.\n",
        "\n",
        "#### 🏗 What We’ll Do:\n",
        "1. Load the same `xtremedistil` BERT model with attention outputs.\n",
        "2. **Freeze all layers except Layer 5 (the last one)**.\n",
        "3. Add a **[CLS]-based classifier** (simple linear layer).\n",
        "4. Build a custom model class that returns both predictions and attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Custom model that freezes all but last attention layer\n",
        "\n",
        "from transformers import AutoModel\n",
        "import torch.nn as nn\n",
        "\n",
        "class BertWithLastLayerAttentionClassifier(nn.Module):\n",
        "    def __init__(self, model_name, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name, output_attentions=True)\n",
        "        \n",
        "        # Freeze all layers except the last encoder layer\n",
        "        for name, param in self.bert.named_parameters():\n",
        "            # Only unfreeze Layer 5 and classifier\n",
        "            if \"encoder.layer.5\" not in name and \"pooler\" not in name:\n",
        "                param.requires_grad = False\n",
        "        \n",
        "        # Classification head on [CLS]\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Get hidden states and attention maps\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            output_attentions=True)\n",
        "        \n",
        "        last_hidden_state = outputs.last_hidden_state  # (batch, seq_len, hidden)\n",
        "        cls_embedding = last_hidden_state[:, 0, :]     # Take [CLS] token representation\n",
        "        logits = self.classifier(cls_embedding)        # Binary classification logits\n",
        "\n",
        "        return logits, outputs.attentions  # Also return attention weights\n",
        "\n",
        "model_name = \"microsoft/xtremedistil-l6-h256-uncased\"\n",
        "finetune_model = BertWithLastLayerAttentionClassifier(model_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🏋️ Step 4: Training the Model (Only Last Layer + Classifier)\n",
        "\n",
        "Now that our model is set up to fine-tune **only the last attention layer and the classifier**, we’ll define the training loop.\n",
        "\n",
        "#### 🧪 What We’ll Do:\n",
        "1. Use **cross-entropy loss** for binary classification (IMDB: positive vs. negative).\n",
        "2. Track accuracy during training and validation.\n",
        "3. Use `AdamW` optimizer — designed for transformer architectures.\n",
        "4. Train for a few epochs to observe how the model adapts.\n",
        "\n",
        "Since we are fine-tuning only a small number of parameters, **training is faster** and lets us isolate the **effect of attention change** during learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bec3c584d82e4f8d985eb482125aec86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6896, Train Accuracy: 0.5415\n",
            "Val Loss: 0.6768, Val Accuracy: 0.5977\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd76b065a2564018ab9e619ced2fa6b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 2:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6729, Train Accuracy: 0.6045\n",
            "Val Loss: 0.6591, Val Accuracy: 0.5977\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1013e0b0965487796c54ac6e64aa950",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 3:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6545, Train Accuracy: 0.6205\n",
            "Val Loss: 0.6410, Val Accuracy: 0.6191\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ac2823a3b66442e87f756f0522966d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 4:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6307, Train Accuracy: 0.6445\n",
            "Val Loss: 0.6263, Val Accuracy: 0.6484\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff73fbe840c84176b54678e1b65afa1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 5:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6182, Train Accuracy: 0.6605\n",
            "Val Loss: 0.5779, Val Accuracy: 0.7070\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "655726f245364c27818c321b65e7a525",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 6:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5984, Train Accuracy: 0.6850\n",
            "Val Loss: 0.5744, Val Accuracy: 0.6953\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d55625bcfbc0448bb8086ea81a11d016",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 7:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5800, Train Accuracy: 0.6985\n",
            "Val Loss: 0.5776, Val Accuracy: 0.7070\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34b44074aa2f4ec999d1a31387dec182",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 8:   0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Step 4: Training setup\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "finetune_model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(filter(lambda p: p.requires_grad, finetune_model.parameters()), lr=2e-5)\n",
        "\n",
        "# Accuracy function\n",
        "def compute_accuracy(preds, labels):\n",
        "    return (preds.argmax(dim=1) == labels).float().mean().item()\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, train_loader, test_loader, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss, total_acc = 0, 0\n",
        "        \n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            \n",
        "            # Check if label key exists, otherwise check for labels\n",
        "            if \"label\" in batch:\n",
        "                labels = batch[\"label\"].to(device)\n",
        "            elif \"labels\" in batch:\n",
        "                labels = batch[\"labels\"].to(device)\n",
        "            else:\n",
        "                raise KeyError(\"No label found in batch. Make sure your dataset includes 'label' or 'labels' field.\")\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits, _ = model(input_ids, attention_mask)\n",
        "            loss = loss_fn(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_acc += compute_accuracy(logits, labels)\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        avg_acc = total_acc / len(train_loader)\n",
        "        print(f\"Train Loss: {avg_loss:.4f}, Train Accuracy: {avg_acc:.4f}\")\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_acc = 0, 0\n",
        "            for batch in test_loader:\n",
        "                input_ids = batch[\"input_ids\"].to(device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(device)\n",
        "                \n",
        "                # Check if label key exists, otherwise check for labels\n",
        "                if \"label\" in batch:\n",
        "                    labels = batch[\"label\"].to(device)\n",
        "                elif \"labels\" in batch:\n",
        "                    labels = batch[\"labels\"].to(device)\n",
        "                else:\n",
        "                    raise KeyError(\"No label found in batch. Make sure your dataset includes 'label' or 'labels' field.\")\n",
        "\n",
        "                logits, _ = model(input_ids, attention_mask)\n",
        "                loss = loss_fn(logits, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                val_acc += compute_accuracy(logits, labels)\n",
        "\n",
        "        avg_val_loss = val_loss / len(test_loader)\n",
        "        avg_val_acc = val_acc / len(test_loader)\n",
        "        print(f\"Val Loss: {avg_val_loss:.4f}, Val Accuracy: {avg_val_acc:.4f}\")\n",
        "\n",
        "# Run training\n",
        "train_model(finetune_model, train_loader, test_loader, epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔍 Step 5: Visualizing Post-Fine-Tuning Attention (Layer 5)\n",
        "\n",
        "Now comes the most insightful part of this notebook:  \n",
        "> **How has attention changed after fine-tuning?**\n",
        "\n",
        "We will:\n",
        "\n",
        "1. Pass a test sentence through the **fine-tuned model**.\n",
        "2. Extract **attention weights from Layer 5** (the only layer we allowed to change).\n",
        "3. Compare this with the attention patterns we saw **before fine-tuning**.\n",
        "4. Interpret how the model’s focus has shifted — especially around sentiment-bearing words.\n",
        "\n",
        "This will help us understand how BERT adapts attention when trained for a specific task (like sentiment classification).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_attention_from_finetuned(model, sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "    \n",
        "    # Remove token_type_ids if present since the model doesn't expect it\n",
        "    if 'token_type_ids' in inputs:\n",
        "        inputs.pop('token_type_ids')\n",
        "    \n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        logits, attentions = model(**inputs)\n",
        "    \n",
        "    token_list = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "    return attentions[-1][0].cpu(), token_list\n",
        "\n",
        "attention_fine_tune, tokens = get_attention_from_finetuned(finetune_model, sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s now visualize all 8 attention heads in **Layer 5** after fine-tuning.\n",
        "This will help us see if:\n",
        "- `[CLS]` has gained stronger focus (for classification)\n",
        "- Heads now better lock on to sentiment cues like `good`, `enjoyed`, or `surprisingly`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reuse our visualization tool from earlier\n",
        "\n",
        "def plot_heads_after_finetuning(tokens, attn_layer, after=True):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import numpy as np\n",
        "\n",
        "    num_heads = attn_layer.shape[0]\n",
        "    fig, axes = plt.subplots(nrows=int(np.ceil(num_heads/4)), ncols=min(4, num_heads),\n",
        "                             figsize=(16, 3*int(np.ceil(num_heads/4))))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i in range(num_heads):\n",
        "        sns.heatmap(attn_layer[i].numpy(), xticklabels=tokens, yticklabels=tokens,\n",
        "                    cmap=\"viridis\", ax=axes[i], cbar=False)\n",
        "        axes[i].set_title(f\"Head {i}\")\n",
        "        axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=90)\n",
        "        axes[i].set_yticklabels(axes[i].get_yticklabels(), rotation=0)\n",
        "\n",
        "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
        "    fig.colorbar(axes[0].collections[0], cax=cbar_ax)\n",
        "\n",
        "    if after:\n",
        "        plt.suptitle(\"Layer 5 Attention Heads (After Fine-Tuning)\", fontsize=16)\n",
        "    else:\n",
        "        plt.suptitle(\"Layer 5 Attention Heads (Before Fine-Tuning)\", fontsize=16)\n",
        "    plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# Run visualization\n",
        "plot_heads_after_finetuning(tokens, attentions[-1][0], after=False)\n",
        "plot_heads_after_finetuning(tokens, attention_fine_tune, after=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🧠 Key Takeaways — Layer 5 Attention Changes After Fine-Tuning\n",
        "\n",
        "Here’s a head-by-head comparison showing how attention patterns **evolved** after fine-tuning BERT on the IMDB sentiment classification task.\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔸 **Head 0**  \n",
        "- **Before**: Attended broadly to `[CLS]`, `[SEP]`, and mid-sentence tokens like `movie`, `was`, `surprisingly`, `good`.  \n",
        "- **After**: Much sharper, **heavily focuses on `was`, `movie`, `surprisingly`, and `good`** — clear sentiment alignment.\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔸 **Head 1**  \n",
        "- **Before**: Focused on `surprisingly`, `good`, `really`, and `enjoyed`.  \n",
        "- **After**: Refined and intensified — now strongly attends to **`surprisingly`, `good`, and `enjoyed`**, with minor focus on `movie` and `really`.\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔸 **Head 2**  \n",
        "- **Before**: Fairly balanced — attention spread across `[CLS]`, `[SEP]`, `was`, `it`, and `the`.  \n",
        "- **After**: Dramatically simplified — now **focuses almost entirely on `was`**, indicating task-specific tuning.\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔸 **Head 3**  \n",
        "- **Before**: Narrow focus on `surprisingly` and `was`.  \n",
        "- **After**: almost **Unchanged** — maintains sharp focus on `surprisingly` and `was`.\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔸 **Head 4**  \n",
        "- **Before**: Attended to structure words like `the`, `movie`, `i`, `it`, and punctuation.  \n",
        "- **After**: **More diffuse**, with slightly increased focus toward the **end of the sentence**.\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔸 **Head 5**  \n",
        "- **Before**: Focused nearly exclusively on `was`.  \n",
        "- **After**: Still strong on `was`, but now adds meaningful attention to **`good`** — sentiment refinement.\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔸 **Head 6**  \n",
        "- **Before**: Emphasis on `[CLS]` and `the`, possibly for sentence-wide summary.  \n",
        "- **After**: **Shifts focus to the beginning** (`[CLS]`, `the`, `movie`) and **last token** — suggesting stronger **sentence boundary modeling**.\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔸 **Head 7**  \n",
        "- **Before**: Primary attention on `was`, with some spread to `[CLS]` and `[SEP]`.  \n",
        "- **After**: Tightens up — now mostly targets **`was` and `good`**.\n",
        "\n",
        "---\n",
        "\n",
        "### 📌 Summary\n",
        "\n",
        "- Attention after fine-tuning is more **task-specific**, **concentrated**, and **semantic-aware**.\n",
        "- Sentiment-rich words (`good`, `enjoyed`, `surprisingly`) receive **much stronger focus**.\n",
        "- `[CLS]` becomes more strategically attended to in certain heads (for classification).\n",
        "- Some heads **specialize**, while others broaden slightly to **reinforce sentence structure**.\n",
        "\n",
        "These changes reflect how attention is **actively re-learned** to support a new task — in this case, **sentiment classification**.\n",
        "\n",
        "## ✅ Conclusion — What We Learned About Attention in BERT\n",
        "\n",
        "Over the course of this notebook, we’ve taken a **deep dive into BERT’s attention mechanism**, starting from raw pretrained behavior all the way to its adaptation through fine-tuning.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔍 What We Did\n",
        "\n",
        "1. **Visualized raw attention** across all heads in Layer 0 and Layer 5 of `xtremedistil` BERT.\n",
        "   - Layer 0: Showed basic structural patterns like self-attention, previous/next token focus.\n",
        "   - Layer 5: Began to specialize — focusing on `[CLS]`, sentiment phrases like `good`, `enjoyed`.\n",
        "\n",
        "2. **Fine-tuned only the last attention layer + a classifier** on IMDB sentiment data.\n",
        "   - All other weights were frozen.\n",
        "   - Training was fast and interpretable.\n",
        "\n",
        "3. **Visualized Layer 5 again after fine-tuning** to inspect what changed.\n",
        "\n",
        "---\n",
        "\n",
        "### 🧠 What We Learned\n",
        "\n",
        "- ✅ **Attention is task-aware**: After fine-tuning, heads shifted focus toward words like `good`, `enjoyed`, `surprisingly` — all sentiment-laden tokens.\n",
        "- ✅ **[CLS] gets re-prioritized**: Many heads increased attention to `[CLS]` after training — a crucial move since it's used for sentence-level prediction.\n",
        "- ✅ **Head specialization improves**: Some heads become tightly focused, others maintain structure — supporting both meaning and form.\n",
        "- ✅ **Interpretability is possible**: By visualizing and tracking attention, we can understand what the model “cares about” during learning.\n",
        "\n",
        "---\n",
        "\n",
        "### 🎓 Takeaway\n",
        "\n",
        "> BERT isn't just a black box.  \n",
        "> Its attention patterns reflect real linguistic and semantic structure —  \n",
        "> and those patterns evolve as it learns specific tasks.\n",
        "\n",
        "With the right tools and a bit of curiosity, **we can peek inside the model** and watch it think."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "planckteam",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
